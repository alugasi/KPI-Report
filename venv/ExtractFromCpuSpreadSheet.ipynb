{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include json and os librareries\n",
    "import json\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Globals:\n",
    "JSON_DIR=\"ExtractTestsResults/JsonTestsFolders/cpuUtil/cpu_util-\"\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#                                                                          #\n",
    "#                    #################################                     #\n",
    "#                    #      Helper functions         #                     #\n",
    "#                    #################################                     #\n",
    "#                                                                          #\n",
    "############################################################################\n",
    "\n",
    "\n",
    "def add_to_os_daemon_list(os_daemon_list:dict, row):\n",
    "    \"\"\"\n",
    "    insert a row to the os daemon list\\n\n",
    "    params:\n",
    "        -os_daemon_list(list)-a list that contain all the oc daemon components of a iteration of ocp version with specific build.\\n\n",
    "        -row-pandas row\n",
    "    returns: the updated os daemon dict.\n",
    "    \"\"\"\n",
    "    group_name = row[\"Component\"].split('\"')[1]\n",
    "    max_cpu = row[\"CPU\"]\n",
    "    os_daemon_list.append({\"group_name\":group_name, \"avg_cpu\":max_cpu})\n",
    "\n",
    "    return os_daemon_list\n",
    "\n",
    "\n",
    "def add_to_infra_pods_list(infra_pods_list:list, row):\n",
    "    \"\"\"\n",
    "    insert a row to the infra pods list\\n\n",
    "    params:\n",
    "        -infra_pods_list(list)-a list that contain all the inftra pods components of a iteration of ocp version with specific build.\\n\n",
    "        -row-pandas row\n",
    "    returns: the updated infra pods dict.\n",
    "    \"\"\"\n",
    "    namespace = row[\"Component\"].split('=')[1].split(\",\")[0].replace(\"\\\"\", \"\")\n",
    "    pod = row[\"Component\"].split('=')[2].split(\"}\")[0].replace(\"\\\"\", \"\")\n",
    "    max_cpu = row[\"CPU\"]\n",
    "    infra_pods_list.append({\"namespace\":namespace, \"pod\":pod,\"avg_cpu\":max_cpu})\n",
    "\n",
    "    return infra_pods_list\n",
    "\n",
    "\n",
    "def iter_grouped_components(iter_components_result_df):\n",
    "    \"\"\"\n",
    "    extract all the fields from a grouped components(rows are grouped by the same ocp verison, ocp build and iteration),\\n\n",
    "    params:\n",
    "        -iter_components_result_df(df)-grouped dataframe\n",
    "    returns: oc daemon and infra pods lists, duration, avg_cpu_total and node name, iteration, kernel and sideloaded\\n.\n",
    "    \"\"\"\n",
    "    infra_pods_list = []\n",
    "    os_daemon_list = []\n",
    "    #get global params:\n",
    "    steady_total_avg =  iter_components_result_df[\"Steady Workloads - Avg\"].unique()\n",
    "    avg_cpu_total = steady_total_avg[0] if steady_total_avg[0] != \"\" else steady_total_avg[1]\n",
    "    duration = iter_components_result_df[\"Duration\"].unique()[0]\n",
    "    iteration = int(iter_components_result_df[\"Iteration\"].unique()[0])\n",
    "    node_name = iter_components_result_df[\"Cluster\"].unique()[0]\n",
    "    kernel = iter_components_result_df[\"Kernel\"].unique()[0] if \"Kernel\" in(iter_components_result_df.columns) else \"\"\n",
    "    sideloaded = iter_components_result_df[\"Sideloaded\"].get(key=0, default=None) if \"Sideloaded\" in(iter_components_result_df.columns) else \"\"\n",
    "    if len(sideloaded) > 0:\n",
    "        sideloaded = \"true\" if sideloaded == \"Yes\" else \"false\"\n",
    "    #update components lists\n",
    "    for _, row in iter_components_result_df.iterrows():\n",
    "        \n",
    "        #update components lists\n",
    "        if \"namespace=\" in row[\"Component\"]:\n",
    "            infra_pods_list = add_to_infra_pods_list(infra_pods_list=infra_pods_list,row=row)\n",
    "        else: \n",
    "            os_daemon_list = add_to_os_daemon_list(os_daemon_list=os_daemon_list, row=row)\n",
    "    \n",
    "    return infra_pods_list, os_daemon_list, avg_cpu_total, duration, node_name, kernel, sideloaded, iteration\n",
    "\n",
    "def extract_types_of_scenario(results_df):\n",
    "    \"\"\"\n",
    "    extract all types metrics of specific scenario.\\n\n",
    "    params:\n",
    "        -results_df(df)-grouped dataframe by the same scenario value\n",
    "    returns: list of types metrics\n",
    "    \"\"\"\n",
    "    types_list = []\n",
    "    total = results_df[\"Max CPU\"].unique()\n",
    "    total_max_cpu = total[0] if total[0] != \"\" else total[1]\n",
    "    for _, row in results_df.iterrows():\n",
    "        types_list.append({\"type_name\":row[\"Type\"], \"max_cpu\":row[\"CPU\"]})\n",
    "    \n",
    "    #add total metrics\n",
    "    types_list.append({\"type_name\":\"total\", \"max_cpu\":total_max_cpu})\n",
    "\n",
    "    return types_list\n",
    "\n",
    "def create_json(results_dict:dict, JSON_DIR:str):\n",
    "    #create json object\n",
    "    #add uniuqe id to file name (using unix time)\n",
    "    timestamp = str(time.time()).replace('.', '')\n",
    "    # open a file and write the JSON data to it\n",
    "    with open(JSON_DIR+timestamp+\".json\", \"w\") as json_file:\n",
    "        json.dump(results_dict, json_file)\n",
    "\n",
    "\n",
    "def add_steadyworkload_metrics(scenario_dict:dict, os_daemon_list:list, infra_pods_list:list, avg_cpu_total:float, duration:str):\n",
    "    scenario_dict[\"components_os_daemon\"] = os_daemon_list\n",
    "    scenario_dict[\"components_infra_pods\"] = infra_pods_list\n",
    "    scenario_dict[\"avg_cpu_total\"] = avg_cpu_total\n",
    "    scenario_dict[\"duration\"] = duration\n",
    "    return scenario_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_components_df = pd.read_csv(\"RAN QE CPU Utilization - component.csv\").fillna(\"\")\n",
    "cpu_scenarios_df = pd.read_csv(\"RAN QE CPU Utilization - other.csv\").fillna(\"\")\n",
    "cpu_components_df[\"OCP Version\"] = cpu_components_df[\"OCP Version\"].astype(\"str\")\n",
    "cpu_scenarios_df[\"OCP Version\"] = cpu_scenarios_df[\"OCP Version\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_components = cpu_components_df.groupby([\"Version\", \"OCP Version\", \"Iteration\"])\n",
    "grouped_scenarios = cpu_scenarios_df.groupby([\"Version\", \"OCP Version\", \"Iteration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating json file for (4.11, '4.11.22', 1)\n"
     ]
    }
   ],
   "source": [
    "for version_iter_key, iter_components_result_df in grouped_components:\n",
    "    print(\"creating json file for {}\".format(version_iter_key))\n",
    "    ocp_version = str(version_iter_key[0])\n",
    "    ocp_build = str(version_iter_key[1])\n",
    "    #extract global params and components values\n",
    "    infra_pods_list, os_daemon_list, avg_cpu_total, duration, node_name, kernel, sideloaded, iteration = iter_grouped_components(iter_components_result_df)\n",
    "    #extract scenarios metrics\n",
    "    iter_scenarios_result_df = grouped_scenarios.get_group(version_iter_key) if version_iter_key in grouped_scenarios.groups else None\n",
    "    scenarios_list = []\n",
    "    if iter_scenarios_result_df is not None:\n",
    "        for scenario, results in iter_scenarios_result_df.groupby(\"Scenario\"):\n",
    "            scenario_dict = {}\n",
    "            scenario_dict[\"scenario_name\"] = scenario\n",
    "            scenario_dict[\"types\"] = extract_types_of_scenario(results_df=results)\n",
    "            if scenario == \"steadyworkload\":\n",
    "                scenario_dict = add_steadyworkload_metrics(scenario_dict=scenario_dict, os_daemon_list=os_daemon_list, \n",
    "                                            infra_pods_list=infra_pods_list, avg_cpu_total=avg_cpu_total, \n",
    "                                            duration=duration)\n",
    "            scenarios_list.append(scenario_dict)\n",
    "    else:\n",
    "        scenario_dict = {}\n",
    "        scenario_dict[\"scenario_name\"] = \"steadyworkload\"\n",
    "        scenario_dict = add_steadyworkload_metrics(scenario_dict=scenario_dict, os_daemon_list=os_daemon_list, \n",
    "                                            infra_pods_list=infra_pods_list, avg_cpu_total=avg_cpu_total, \n",
    "                                            duration=duration)\n",
    "        scenarios_list.append(scenario_dict)\n",
    "        \n",
    "\n",
    "    results_dict = {\"ocp_version\":ocp_version, \"ocp_build\":ocp_build, \"test_type\":\"cpu_util\",\\\n",
    "                    \"iteration\":iteration, \"node_name\":node_name, \"kernel\":kernel, \"sideloaded\":sideloaded, \"scenarios\":scenarios_list}\n",
    "    create_json(results_dict=results_dict, JSON_DIR=JSON_DIR)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('data': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36996c97f3a513c7539113157ff2a07191b199a8c1a7349bbd76d49dcb155f46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
